{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Hate Speech Rocognition System**\n",
        "\n",
        "Following is the Code Written by us for Hate Speech Recognition System\n",
        "\n",
        "**Mounting The Drive**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xs3C4qCiJ5Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8FOYv_V0vNu",
        "outputId": "e0c76860-ab79-4827-b50a-18b8d35119a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing important Libraries**"
      ],
      "metadata": {
        "id": "Zhs5FK3HNfrm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ki6atd8-utK3"
      },
      "outputs": [],
      "source": [
        "#Importing the packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn. feature_extraction. text import CountVectorizer\n",
        "from sklearn. model_selection import train_test_split\n",
        "from sklearn. tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setting Up The Enviorment**\n",
        "\n",
        " nltk: natural language tool kit\n",
        "\n",
        " re: regular expression\n",
        "\n",
        " In the Follwing Piece of code we have downloaded package stopwords to ignore some collection of common words during analysis, and used a stemmer (snowball) for reducing words to their base or root form, which helps in simplifying text and capturing the core meaning."
      ],
      "metadata": {
        "id": "y6XBFKxzOlAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from nltk. corpus import stopwords\n",
        "stopword=set(stopwords.words('english'))\n",
        "stemmer = nltk. SnowballStemmer(\"english\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np5ZgVEvwkoi",
        "outputId": "8b078c5d-3556-4c6c-8143-093344080eca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading the Data Set from File**\n",
        "\n",
        "reading the first few rows from the data set"
      ],
      "metadata": {
        "id": "m9e7l1yEUEWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd. read_csv(\"/content/drive/MyDrive/ML_Project/labeled_data.csv\")\n",
        "#To preview the data\n",
        "print(data. head())"
      ],
      "metadata": {
        "id": "x-9R8uUdxTaP",
        "outputId": "75553791-8ba1-41b2-cbcd-d6fb4d0c1bb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
            "0           0      3            0                   0        3      2   \n",
            "1           1      3            0                   3        0      1   \n",
            "2           2      3            0                   3        0      1   \n",
            "3           3      3            0                   2        1      1   \n",
            "4           4      6            0                   6        0      1   \n",
            "\n",
            "                                               tweet  \n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding New Columns\n",
        "**\"labels\"** to the dataframe \"data\" which is based on the values in the exissting class column\n",
        "\n",
        "After that we selected tweet and labels cloumns and print the first few rows of the modified **dataframe**"
      ],
      "metadata": {
        "id": "ETlYQcQIdxtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"labels\"] = data[\"class\"]. map({0: \"Hate Speech\", 1: \"Offensive Speech\", 2: \"No Hate and Offensive Speech\"})\n",
        "data = data[[\"tweet\", \"labels\"]]\n",
        "print(data. head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqYFnwy61Fy5",
        "outputId": "57627cfe-98b0-4d97-b79e-c3a38eef0194"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               tweet  \\\n",
            "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
            "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
            "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
            "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
            "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
            "\n",
            "                         labels  \n",
            "0  No Hate and Offensive Speech  \n",
            "1              Offensive Speech  \n",
            "2              Offensive Speech  \n",
            "3              Offensive Speech  \n",
            "4              Offensive Speech  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning**\n",
        "\n",
        "ere we have cleaned the text by calling cleaning function and applying that clean() to the dataset."
      ],
      "metadata": {
        "id": "EyQ0dnOQfWJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def clean (text):\n",
        " text = str (text). lower()\n",
        " text = re. sub('[.?]', '', text)\n",
        " text = re. sub('https?://\\S+|www.\\S+', '', text)\n",
        " text = re. sub('<.?>+', '', text)\n",
        " text = re. sub('[%s]' % re. escape(string. punctuation), '', text)\n",
        " text = re. sub('\\n', '', text)\n",
        " text = re. sub('\\w\\d\\w', '', text)\n",
        " text = [word for word in text.split(' ') if word not in stopword]\n",
        " text=\" \". join(text)\n",
        " text = [stemmer. stem(word) for word in text. split(' ')]\n",
        " text=\" \". join(text)\n",
        " return text\n",
        "data[\"tweet\"] = data[\"tweet\"]. apply(clean)"
      ],
      "metadata": {
        "id": "FxpYb4Vl1Im6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**\n",
        "\n",
        "Here we will extract features from the labels and will do text vactorization with count vectorizer and after that Splitting the dataset into training and testing sets. The feature matrix X and label array y are divided into training (X_train, y_train) and testing (X_test, y_test) sets, with a 33% test size and a fixed random state for reproducibility."
      ],
      "metadata": {
        "id": "by8TABWJgQME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np. array(data[\"tweet\"])\n",
        "y = np. array(data[\"labels\"])\n",
        "cv = CountVectorizer()\n",
        "X = cv. fit_transform(x)\n",
        "# Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "wdpJ3oxW1pUy"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Building And Training**\n",
        "\n",
        "Training the Decision Tree Classifier using the training data (X_train and y_train). Here model is learning patterns and relationships in the text data to make predictions on new and unseen data."
      ],
      "metadata": {
        "id": "oG63SXG1h4Ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model building\n",
        "model = DecisionTreeClassifier()\n",
        "#Training the model\n",
        "model. fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "P98ACI2S1wT6",
        "outputId": "43bca36e-b952-4416-fa41-73fd3049562d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model testing**\n",
        "Using the trained Decision Tree Classifier model to make predictions on the test set (X_test). The variable y_pred now contains the predicted labels for the test data."
      ],
      "metadata": {
        "id": "RtTGaybViqT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the model\n",
        "y_pred = model. predict (X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G47-M4V-15OG",
        "outputId": "13760770-7c25-45b4-82a0-43c86d51530a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Offensive Speech', 'Offensive Speech', 'Offensive Speech', ...,\n",
              "       'No Hate and Offensive Speech', 'Offensive Speech',\n",
              "       'Offensive Speech'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**\n",
        "Now here we will use predefined functions to calculate te Accurracy."
      ],
      "metadata": {
        "id": "2cD8Tt2Yje8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy Score of our model\n",
        "from sklearn. metrics import accuracy_score\n",
        "print (accuracy_score (y_test,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyLl-Prv2A-o",
        "outputId": "f15db948-6ffc-45f7-8b10-b58b1b13245b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8788360435261034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the outcome\n",
        "inp = \"Hye You piece of shit!!!\"\n",
        "inp = cv.transform([inp]).toarray()\n",
        "print(model.predict(inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX47_Y-v2IXv",
        "outputId": "987b12cf-74bd-4c5b-c9ba-3ce0fa0bd59d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Offensive Speech']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = \"It is really awesome\"\n",
        "inp = cv. transform([inp]). toarray()\n",
        "print(model. predict(inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVnMxXPw2PCM",
        "outputId": "19a460f4-e2f4-4964-acd4-a9976c3fdc38"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No Hate and Offensive Speech']\n"
          ]
        }
      ]
    }
  ]
}